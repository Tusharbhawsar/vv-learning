{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf24a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# i_value = \"yXuxKG9KF\"\n",
    "# url = f\"https://api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     out=open(\"josn_data.json\",\"w\")\n",
    "#     json.dump(data,out)\n",
    "#     print(data)# else:\n",
    "#     print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75e4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# i_value = \"yXuxKG9KF\"\n",
    "# url = f\"https://api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "# # video_url\n",
    "# response = requests.get(url)\n",
    "# jsonn=response.json()\n",
    "# clips=jsonn.get(\"clips\",[])\n",
    "\n",
    "# for clip in clips:\n",
    "#     urls=clip.get(\"video_url\")\n",
    "#     print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d104110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# i_value = \"yXuxKG9KF\"\n",
    "# url = f\"https://api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     with open(\"json_data.json\", \"w\") as out:\n",
    "#         json.dump(data, out, indent=4)\n",
    "# #     print(json.dumps(data, indent=4))\n",
    "#     video_urls = []\n",
    "#     if 'clips' in data:\n",
    "#         for clip in data['clips']:\n",
    "#             video_url = clip.get('video_url')  \n",
    "#             if not video_url:  \n",
    "#                 edited_videos = clip.get('editedVideos', [])\n",
    "#                 for edited_clip in edited_videos:\n",
    "#                     video_url = edited_clip.get('video_url')\n",
    "#                     if video_url:\n",
    "#                         video_urls.append(video_url)\n",
    "\n",
    "#     if video_urls:\n",
    "#         print(\"Video URLs:\")\n",
    "#         for i,video_url in enumerate(video_urls):\n",
    "#             print(video_url)\n",
    "#     else:\n",
    "#         print(\"No video URLs found in the response.\")\n",
    "# else:\n",
    "#     print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52f5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# i_value = \"yXuxKG9KF\"\n",
    "# url = f\"https://api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     with open(\"json_data.json\", \"w\") as out:\n",
    "#         json.dump(data, out, indent=4)\n",
    "    \n",
    "#     video_urls = set()  \n",
    "#     if 'clips' in data:\n",
    "#         for clip in data['clips']:\n",
    "#             video_url = clip.get('video_url')  \n",
    "#             if not video_url:  \n",
    "#                 edited_videos = clip.get('editedVideos', [])\n",
    "#                 for edited_clip in edited_videos:\n",
    "#                     video_url = edited_clip.get('video_url')\n",
    "#                     if video_url:\n",
    "#                         video_urls.add(video_url)  \n",
    "            \n",
    "#             if video_url:\n",
    "#                 video_urls.add(video_url) \n",
    "\n",
    "#     if video_urls:\n",
    "#         print(\"Video URLs:\")\n",
    "#         for video_url in video_urls:\n",
    "#             print(video_url)\n",
    "        \n",
    "#         with open(\"video_urls.txt\", \"w\") as url_file:\n",
    "#             for video_url in video_urls:\n",
    "#                 url_file.write(video_url + \"\\n\")\n",
    "                \n",
    "#         print(\"Video URLs saved to video_urls.txt\")\n",
    "        \n",
    "#     else:\n",
    "#         print(\"No video URLs found in the response.\")\n",
    "\n",
    "# else:\n",
    "#     print(f\"Failed to fetch data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f8295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####working\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# i_value = \"iEVvejwdQ\"\n",
    "# url = f\"https://api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     with open(\"json_data.json\", \"w\") as out:\n",
    "#         json.dump(data, out, indent=4)\n",
    "# #     print(json.dumps(data, indent=4))\n",
    "#     video_urls = []\n",
    "#     if 'clips' in data:\n",
    "#         for clip in data['clips']:\n",
    "#             video_url = clip.get('video_url')  \n",
    "#             if not video_url:  \n",
    "#                 edited_videos = clip.get('editedVideos', [])\n",
    "#                 for edited_clip in edited_videos:\n",
    "#                     video_url = edited_clip.get('video_url')\n",
    "#                     if video_url:\n",
    "#                         video_urls.append(video_url)\n",
    "\n",
    "#     if video_urls:\n",
    "#         print(\"Video URLs:\")\n",
    "#         for video_url in video_urls:\n",
    "#             print(video_url)\n",
    "#     else:\n",
    "#         print(\"No video URLs found in the response.\")\n",
    "# else:\n",
    "#     print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a1c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# i_value = \"iEVvejwdQ\"\n",
    "# url = f\"https://api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     with open(\"json_data.json\", \"w\") as out:\n",
    "#         json.dump(data, out, indent=4)\n",
    "# #     print(json.dumps(data, indent=4))\n",
    "#     video_urls = []\n",
    "#     in_urls = []\n",
    "#     if 'clips' in data:\n",
    "#         for clip in data['clips']:\n",
    "#             video_url = clip.get('video_url')\n",
    "#             input_url=clip.get(\"videoUrl\")\n",
    "# #             print(video_url)\n",
    "# #             print(input_url)\n",
    "#             if not video_url:  \n",
    "#                 edited_videos = clip.get('editedVideos', [])\n",
    "#                 for edited_clip in edited_videos:\n",
    "#                     video_url = edited_clip.get('video_url')\n",
    "#                     input_url=edited_clip.get(\"videoUrl\")\n",
    "#                     if video_url:\n",
    "#                         video_urls.append(video_url)\n",
    "#                         in_urls.append(video_url)\n",
    "                        \n",
    "#     for video_url in video_urls:\n",
    "#         print(\"autofilp\",video_url)\n",
    "#     for inn in in_urls:\n",
    "#         print(\"input\",inn)\n",
    "        \n",
    "# #     if video_urls:\n",
    "# # #         print(\"Video URLs:\")\n",
    "# #         for video_url in video_urls:\n",
    "# # #             print(video_url)\n",
    "# #     else:\n",
    "# #         print(\"No video URLs found in the response.\")\n",
    "# # else:\n",
    "# #     print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c12918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perfect\n",
    "import requests\n",
    "import json\n",
    "\n",
    "i_value = \"yTa-MOQah\"\n",
    "url = f\"https://stg.api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    with open(\"json_data.json\", \"w\") as out:\n",
    "        json.dump(data, out, indent=4)\n",
    "#     print(json.dumps(data, indent=4))\n",
    "    video_urls = []\n",
    "    in_urls = []\n",
    "    for clip in data['clips']:\n",
    "        video_url = clip.get('video_url')\n",
    "        input_url=clip.get(\"videoUrl\")\n",
    "        edited_videos = clip.get('editedVideos', [])\n",
    "        for edited_clip in edited_videos:\n",
    "            video_url = edited_clip.get('video_url')\n",
    "            input_url=edited_clip.get(\"videoUrl\")\n",
    "            \n",
    "            in_urls.append(input_url)\n",
    "            video_urls.append(video_url)\n",
    "            \n",
    "            print(\"auto\",video_url,\"input\",input_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20381f5-3ec4-4349-99b3-6d7c173e2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto https://d1zxk9teuo4ijt.cloudfront.net/org_faddd2f2-3111-4c09-ade5-800a2c8c6778/OCt01Uaya/Clips/AspectRatio/67690d0af4e6340006d21469/9e4920f6-be43-456f-b6de-2b3ab89b744d.mp4 input https://demxa66ujcbgw.cloudfront.net/org_3c0a446f-9d96-45dd-bd44-c5ea1fdfd719/XW3P6vIJm/Clips/Man/1734870413_9283073/video/1734870413_9283974.mp4\n"
     ]
    }
   ],
   "source": [
    "#saving for csv perfect\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "i_value = \"OCt01Uaya\"\n",
    "url = f\"https://stg.api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "     \n",
    "    recods = []\n",
    "    for clip in data['clips']:\n",
    "        video_url = clip.get('video_url')\n",
    "        input_url=clip.get(\"videoUrl\")\n",
    "        edited_videos = clip.get('editedVideos', [])\n",
    "        for edited_clip in edited_videos:\n",
    "            video_url = edited_clip.get('video_url')\n",
    "            input_url=edited_clip.get(\"videoUrl\")\n",
    "            recods.append({\n",
    "                \"original_input\":input_url,\n",
    "                \"autoflip\":video_url\n",
    "            })\n",
    "    df = pd.DataFrame(recods)\n",
    "    df.to_csv(\"autoflip.csv\",index=False)\n",
    "\n",
    "    print(\"auto\",video_url,\"input\",input_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42d017-d31d-4682-b805-a45651042dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mappint the urls\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "daily_feedback_df = pd.read_csv(\"/home/multi-sy-23/Downloads/autoflip/Autoflip_daily_feedback_file - 22-12-2024.csv\")\n",
    "autoflip_df = pd.read_csv(\"/home/multi-sy-23/Downloads/autoflip/autoflip.csv\")\n",
    "\n",
    "# Create a mapping dictionary for autoflip URLs\n",
    "url_mapping = dict(zip(autoflip_df['original_input'], autoflip_df['autoflip']))\n",
    "\n",
    "# Update the 'output url' column in daily_feedback_df\n",
    "daily_feedback_df['output url'] = daily_feedback_df['video_url'].map(url_mapping).combine_first(daily_feedback_df['output url'])\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "daily_feedback_df.to_csv(\"Updated_Daily_Feedback.csv\", index=False)\n",
    "\n",
    "print(\"Updated file saved as 'Updated_Daily_Feedback.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5493e3b8-85d9-4f8a-827d-f9c6455be808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File converted successfully: output_file.xlsx\n"
     ]
    }
   ],
   "source": [
    "#convert cvs into xlsx\n",
    "import pandas as pd\n",
    "\n",
    "# CSV file ka path\n",
    "csv_file = \"/home/multi-sy-23/Downloads/autoflip/autoflip.csv\"  \n",
    "xlsx_file = \"output_file.xlsx\"  \n",
    "\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "data.to_excel(xlsx_file, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"File converted successfully: {xlsx_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9220f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d6cf2f9-9476-4697-9b81-0973e1ee9201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clips data saved to autoflip.csv\n",
      "Updated file saved as 'Updated_Daily_Feedback.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Fetch clips data and save to CSV\n",
    "i_value = \"yTa-MOQah\"\n",
    "url = f\"https://stg.api.magnifi.ai/get/clips/{i_value}?limit=1000&pageNo=1&filters={{\\\"players\\\":[],\\\"events\\\":[],\\\"sortBy\\\":\\\"TIME_DESCENDANT\\\",\\\"aspectRatio\\\":\\\"\\\",\\\"playBackSpeed\\\":[],\\\"webhookPublish\\\":\\\"\\\",\\\"clipData\\\":{{}}}}&daterange=[]&sort={{\\\"start_time\\\":-1,\\\"_id\\\":1}}&type=all&search=&aspectRatio=&webhookPublish=&isManualUpload=false&skipCount=\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    records = []\n",
    "    for clip in data['clips']:\n",
    "        video_url = clip.get('video_url')\n",
    "        input_url = clip.get(\"videoUrl\")\n",
    "        edited_videos = clip.get('editedVideos', [])\n",
    "        for edited_clip in edited_videos:\n",
    "            video_url = edited_clip.get('video_url')\n",
    "            input_url = edited_clip.get(\"videoUrl\")\n",
    "            records.append({\n",
    "                \"original_input\": input_url,\n",
    "                \"autoflip\": video_url\n",
    "            })\n",
    "    \n",
    "    autoflip_csv_path = \"autoflip.csv\"\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(autoflip_csv_path, index=False)\n",
    "    print(f\"Clips data saved to {autoflip_csv_path}\")\n",
    "\n",
    "    # Step 2: Update daily feedback CSV with autoflip URLs\n",
    "    daily_feedback_path = \"/home/multi-sy-23/Downloads/autoflip/Autoflip_daily_feedback_file - 22-12-2024.csv\"\n",
    "    daily_feedback_df = pd.read_csv(daily_feedback_path)\n",
    "    autoflip_df = pd.read_csv(autoflip_csv_path)\n",
    "\n",
    "    # Create a mapping dictionary for autoflip URLs\n",
    "    url_mapping = dict(zip(autoflip_df['original_input'], autoflip_df['autoflip']))\n",
    "\n",
    "    # Update the 'output url' column in daily_feedback_df\n",
    "    daily_feedback_df['output_url'] = daily_feedback_df['video_url'].map(url_mapping).combine_first(daily_feedback_df['output_url'])\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    updated_feedback_path = \"Updated_Daily_Feedback.csv\"\n",
    "    daily_feedback_df.to_csv(updated_feedback_path, index=False)\n",
    "\n",
    "    print(f\"Updated file saved as '{updated_feedback_path}'\")\n",
    "else:\n",
    "    print(f\"Failed to fetch clips data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec146da9-3408-4c2c-b3d3-8ec8d8f1c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as 'Updated_Daily_Feedback.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "daily_feedback_df = pd.read_csv(\"/home/multi-sy-23/Downloads/autoflip/Autoflip_daily_feedback_file - 20-12-2024.csv\")\n",
    "autoflip_df = pd.read_csv(\"/home/multi-sy-23/Downloads/autoflip/19_20_21_22_.csv\")\n",
    "\n",
    "# Create a mapping dictionary for autoflip URLs\n",
    "url_mapping = dict(zip(autoflip_df['original_input'], autoflip_df['autoflip']))\n",
    "\n",
    "# Update the 'output url' column in daily_feedback_df\n",
    "daily_feedback_df['output url'] = daily_feedback_df['video_url'].map(url_mapping).combine_first(daily_feedback_df['output url'])\n",
    "\n",
    "daily_feedback_df.to_csv(\"Updated_Daily_Feedback.csv\", index=False)\n",
    "\n",
    "print(\"Updated file saved as 'Updated_Daily_Feedback.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3b21a-90b8-42be-a587-0971cf6165ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
